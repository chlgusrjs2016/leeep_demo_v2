# -*- coding: utf-8 -*-
# bot.py

import discord
from discord.ext import commands, tasks
import os
from dotenv import load_dotenv
import google.generativeai as genai
import google.generativeai.types as genai_types # GenerationConfig ì‚¬ìš© ì‹œ í•„ìš”í•  ìˆ˜ ìˆìŒ
import random
import asyncio # Cog ë¡œë”© ìœ„í•´ í•„ìš”
import traceback # ì˜¤ë¥˜ ìƒì„¸ ì¶œë ¥ì„ ìœ„í•´ ì¶”ê°€
from typing import Dict, List # íƒ€ì… íŒíŒ… ìœ„í•´ ì¶”ê°€
import re # ë¬¸ì¥ ë¶„ë¦¬ë¥¼ ìœ„í•´ re ì„í¬íŠ¸

# --- ë‹¤ë¥¸ .py íŒŒì¼ì—ì„œ í•¨ìˆ˜ ë° ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸° ---
try:
    from database import init_db, load_user_data, save_user_data
    import prompts
    print("DEBUG: database.py ë° prompts.py ì„í¬íŠ¸ ì„±ê³µ.")
except ImportError as e:
    print(f"ì˜¤ë¥˜: database.py ë˜ëŠ” prompts.py ì„í¬íŠ¸ ì‹¤íŒ¨! íŒŒì¼ì´ ì¡´ì¬í•˜ê³  ë¬¸ë²• ì˜¤ë¥˜ê°€ ì—†ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ì˜¤ë¥˜: {e}")
    exit()
# -------------------------------------------

# --- .env ë¡œë“œ ë° ë³€ìˆ˜ ì„¤ì • ---
load_dotenv()
DISCORD_TOKEN = os.getenv('DISCORD_TOKEN')
GEMINI_API_KEY = os.getenv('GOOGLE_API_KEY')
DISCORD_APP_ID = os.getenv('DISCORD_APP_ID')
TARGET_USER_ID_STR = os.getenv('TARGET_USER_ID')

# --- ë¹„ë°€ ì •ë³´ ë¡œë“œ í™•ì¸ ---
if not DISCORD_TOKEN: print("ì˜¤ë¥˜: .env íŒŒì¼ì— DISCORD_TOKENì„ ì„¤ì •í•´ì£¼ì„¸ìš”."); exit()
if not GEMINI_API_KEY: print("ì˜¤ë¥˜: .env íŒŒì¼ì— GOOGLE_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."); exit()
if not DISCORD_APP_ID: print("ì˜¤ë¥˜: .env íŒŒì¼ì— DISCORD_APP_IDë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."); exit()
if not TARGET_USER_ID_STR: print("ì˜¤ë¥˜: .env íŒŒì¼ì— TARGET_USER_IDë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."); exit()

try:
    TARGET_USER_ID = int(TARGET_USER_ID_STR)
    print(f"í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ. ì„ í†¡ ëŒ€ìƒ ì‚¬ìš©ì ID: {TARGET_USER_ID}")
except ValueError:
    print(f"ì˜¤ë¥˜: .env íŒŒì¼ì˜ TARGET_USER_ID ('{TARGET_USER_ID_STR}')ê°€ ìœ íš¨í•œ ìˆ«ìê°€ ì•„ë‹™ë‹ˆë‹¤.")
    exit()

# --- Gemini API ì„¤ì • ë° ëª¨ë¸ ì´ˆê¸°í™” ---
try:
    genai.configure(api_key=GEMINI_API_KEY)
    print(f"ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œë¨ (ì¼ë¶€): {prompts.SYSTEM_INSTRUCTION[:100]}...")
    SELECTED_MODEL = 'gemini-1.5-flash-latest'
    # SELECTED_MODEL = 'gemini-1.5-pro-latest' # Pro ëª¨ë¸ ì‚¬ìš© ì‹œ

    model = genai.GenerativeModel(
        SELECTED_MODEL,
        system_instruction=prompts.SYSTEM_INSTRUCTION
    )
    print(f"Gemini API ì„¤ì • ë° ëª¨ë¸({model.model_name}) ì´ˆê¸°í™” ì™„ë£Œ.")
except Exception as e: print(f"Gemini API ì„¤ì • ë˜ëŠ” ëª¨ë¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"); exit()


# --- Discord ë´‡ ì„¤ì • ---
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix='!', intents=intents)


# --- ë©”ì‹œì§€ ë²„í¼ ë° íƒ€ì´ë¨¸ ê´€ë¦¬ìš© ì „ì—­ ë³€ìˆ˜ ---
user_message_buffers: Dict[int, List[discord.Message]] = {}
user_timer_tasks: Dict[int, asyncio.Task] = {}
# ----------------------------------------------------


# --- í˜¸ê°ë„ ê³„ì‚° í•¨ìˆ˜ (ë¹„ë™ê¸°) ---
async def calculate_likability(model, current_score, message_content):
    """ Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ì‹œì§€ ê°ì„±ì„ ë¶„ì„í•˜ê³  ìƒˆë¡œìš´ í˜¸ê°ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. """
    print(f"DEBUG: calculate_likability í˜¸ì¶œë¨ - í˜„ì¬ ì ìˆ˜: {current_score}, ë©”ì‹œì§€: '{message_content[:20]}...'")
    new_score = current_score
    try:
        # Generation Config (ê°ì„± ë¶„ì„ìš© - ì§§ì€ ë‹µë³€ ìœ ë„)
        # genai_types ì„í¬íŠ¸ í•„ìš”
        generation_config_sentiment = genai_types.GenerationConfig(max_output_tokens=50, temperature=0.2)
        sentiment_prompt = prompts.SENTIMENT_ANALYSIS_PROMPT_TEMPLATE.format(user_message=message_content)
        print(f"DEBUG: ê°ì„± ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì „ì†¡ ì‹œë„")
        sentiment_response = await model.generate_content_async(
            sentiment_prompt,
            generation_config=generation_config_sentiment # ìƒì„± ì„¤ì • ì „ë‹¬
        )
        if sentiment_response and sentiment_response.text:
            sentiment = sentiment_response.text.strip().upper()
            print(f"DEBUG: ê°ì„± ë¶„ì„ ê²°ê³¼: {sentiment}")
            if sentiment == "POSITIVE": new_score += 2; print(f"DEBUG: í˜¸ê°ë„ ì¦ê°€! (+2)")
            elif sentiment == "NEGATIVE": new_score -= 1; print(f"DEBUG: í˜¸ê°ë„ ê°ì†Œ! (-1)")
            else: print(f"DEBUG: í˜¸ê°ë„ ë³€ê²½ ì—†ìŒ (ê°ì„±: {sentiment})")
        else: print(f"ê²½ê³ : ê°ì„± ë¶„ì„ API ì‘ë‹µ ë¹„ì—ˆìŒ. í˜¸ê°ë„ ë³€ê²½ ì—†ìŒ.")
    except Exception as e: print(f"ì˜¤ë¥˜: ê°ì„± ë¶„ì„ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. í˜¸ê°ë„ ë³€ê²½ ì—†ìŒ.")
    new_score = max(0, min(100, new_score)) # ì˜ˆ: 0~100ì  ì œí•œ
    print(f"DEBUG: calculate_likability ìµœì¢… ê²°ê³¼ - ìƒˆ ì ìˆ˜: {new_score}")
    return new_score


# --- íƒ€ì´ë¨¸ ë§Œë£Œ ì‹œ ë©”ì‹œì§€ ë¬¶ìŒ ì²˜ë¦¬ í•¨ìˆ˜ ---
async def process_message_batch(user_id: int):
    global user_message_buffers, user_timer_tasks # ì „ì—­ ë³€ìˆ˜ ì‚¬ìš© ëª…ì‹œ
    print(f"DEBUG: process_message_batch ì‹œì‘ - ì‚¬ìš©ì ID: {user_id}")
    if user_id in user_timer_tasks: del user_timer_tasks[user_id]; print(f"DEBUG: process_message_batch - íƒ€ì´ë¨¸ ì‘ì—… ì œê±°ë¨")

    if user_id in user_message_buffers:
        messages_to_process = user_message_buffers.pop(user_id)
        print(f"DEBUG: process_message_batch - ë²„í¼ ë©”ì‹œì§€ ê°€ì ¸ì˜´ (ê°œìˆ˜: {len(messages_to_process)})")
        if not messages_to_process: print(f"DEBUG: ì²˜ë¦¬í•  ë©”ì‹œì§€ ì—†ìŒ"); return

        last_message = messages_to_process[-1]
        author = last_message.author; channel = last_message.channel
        combined_message_content = "\n".join([msg.content for msg in messages_to_process])
        print(f"DEBUG: process_message_batch - í•©ì³ì§„ ë©”ì‹œì§€: '{combined_message_content}'")

        current_history, current_likability = load_user_data(user_id)
        print(f"DEBUG: process_message_batch - ë¡œë“œë¨ -> ê¸°ë¡: {len(current_history)}í„´, í˜¸ê°ë„: {current_likability}")

        history_for_api = current_history.copy()
        history_for_api.append({'role': 'user', 'parts': [combined_message_content]})
        likability_percent = f"{current_likability}%"
        likability_context_prompt = f"(ì‹œìŠ¤í…œ ì»¨í…ìŠ¤íŠ¸: ì°¸ê³ ë¡œ í˜„ì¬ ì´ ì‚¬ìš©ìì™€ ë‚˜ì˜ í˜¸ê°ë„ëŠ” {likability_percent} ì•¼. ì´ í˜¸ê°ë„ %ì™€ ë‚˜ì˜ ì—­í•  ì„¤ì •(System Instruction)ì— ëª…ì‹œëœ ê¸°ì¤€ì— ë”°ë¼ ë§íˆ¬ì™€ íƒœë„ë¥¼ ì—„ê²©í•˜ê²Œ ì¡°ì ˆí•´ì„œ ì‘ë‹µí•´ì•¼ í•´. í˜¸ê°ë„ ì ìˆ˜ ìì²´ë¥¼ ì–¸ê¸‰í•˜ì§€ëŠ” ë§ˆ.)"
        history_for_api.append({'role': 'user', 'parts': [likability_context_prompt]})
        print(f"DEBUG: process_message_batch - API ì „ë‹¬ìš© ê¸°ë¡ ìƒì„±ë¨ (ì´ {len(history_for_api)} í„´)")

        async with channel.typing():
            new_likability = current_likability; save_needed = False
            bot_response_text_full = "" # ìƒì„±ëœ ì „ì²´ ì‘ë‹µ ì €ì¥ìš©
            final_text_to_send = "" # ìµœì¢… ì „ì†¡ í…ìŠ¤íŠ¸

            try:
                print("DEBUG: process_message_batch - 1ë‹¨ê³„: ì „ì²´ ì‘ë‹µ ìƒì„± ì‹œë„...")
                # Generation Config (ê¸¸ì´ ì œí•œ ì œê±°ë¨)
                generation_config = None # ë˜ëŠ” genai_types.GenerationConfig() ê°ì²´

                response = await model.generate_content_async(
                    history_for_api,
                    generation_config=generation_config
                )

                if not (response and response.text): raise Exception("Initial generation failed or blocked")

                bot_response_text_full = response.text.strip()
                print(f"DEBUG: process_message_batch - 1ë‹¨ê³„ ìƒì„± ì „ì²´ ì‘ë‹µ: {bot_response_text_full[:100]}...")

                # 2ë‹¨ê³„: ê¸¸ì´ í™•ì¸ ë° í•„ìš”ì‹œ ìš”ì•½ (3ë¬¸ì¥ ì´ˆê³¼ ì‹œ)
                sentences = re.split(r'(?<=[.?!])\s+', bot_response_text_full)
                if len(sentences) > 3:
                    print(f"DEBUG: process_message_batch - ë‹µë³€ì´ {len(sentences)} ë¬¸ì¥ìœ¼ë¡œ ê¸¸ì–´ì„œ ìš”ì•½ ì‹œë„...")
                    summarized_text = await summarize_text(model, bot_response_text_full)
                    if summarized_text: final_text_to_send = summarized_text
                    else: print("ê²½ê³ : ìš”ì•½ ì‹¤íŒ¨. ì›ë³¸ ë‹µë³€ì˜ ì²« 3ë¬¸ì¥ ì‚¬ìš©."); final_text_to_send = " ".join(sentences[:3])
                else: print("DEBUG: process_message_batch - ë‹µë³€ì´ 3ë¬¸ì¥ ì´í•˜ì´ë¯€ë¡œ ì›ë³¸ ì‚¬ìš©."); final_text_to_send = bot_response_text_full

                # ì„±ê³µ ì‹œ í˜¸ê°ë„ ê³„ì‚°
                new_likability = await calculate_likability(model, current_likability, combined_message_content)
                # ì‹¤ì œ ê¸°ë¡ì—ëŠ” í•­ìƒ ì „ì²´ ì‘ë‹µ ì €ì¥
                current_history.append({'role': 'user', 'parts': [combined_message_content]})
                current_history.append({'role': 'model', 'parts': [bot_response_text_full]}) # ì „ì²´ ì‘ë‹µ ì €ì¥
                save_needed = True

                # 3ë‹¨ê³„: ìµœì¢… í…ìŠ¤íŠ¸ ë¶„í•  ì „ì†¡
                print(f"DEBUG: process_message_batch - ìµœì¢… ì „ì†¡í•  í…ìŠ¤íŠ¸: {final_text_to_send[:100]}...")
                final_sentences = re.split(r'(?<=[.?!])\s+', final_text_to_send)
                for sentence in final_sentences:
                    sentence = sentence.strip()
                    if sentence: await channel.send(sentence); await asyncio.sleep(random.uniform(1.0, 2.0))

            except Exception as e:
                print(f"ì˜¤ë¥˜: User {user_id} ë©”ì‹œì§€ ì²˜ë¦¬(ìš”ì•½ í¬í•¨) ì¤‘ - {e}")
                if not final_text_to_send: await channel.send("ë¯¸ì•ˆ, ë°©ê¸ˆ í•˜ì‹  ë§ì”€ë“¤ì„ ì²˜ë¦¬í•˜ëŠ” ë° ë¬¸ì œê°€ ìƒê²¼ì–´ìš”. ğŸ˜¥")
            finally:
                # DB ì €ì¥ (ì„±ê³µ ì‹œì—ë§Œ)
                if save_needed: print(f"DEBUG: process_message_batch - ì €ì¥ í•¨ìˆ˜ í˜¸ì¶œ ì „ ê¸°ë¡ (ì´ {len(current_history)} í„´), ìƒˆ í˜¸ê°ë„: {new_likability}"); save_user_data(user_id, current_history, new_likability)
                else: print(f"DEBUG: process_message_batch - DB ì €ì¥ ê±´ë„ˆëœ€.")

    else: print(f"DEBUG: process_message_batch - ì‚¬ìš©ì ID {user_id} ë²„í¼ê°€ ì´ë¯¸ ë¹„ì–´ìˆìŒ.")
    if user_id in user_timer_tasks: del user_timer_tasks[user_id]; print(f"DEBUG: process_message_batch - íƒ€ì´ë¨¸ ì‘ì—… ìµœì¢… ì œê±°ë¨")


# --- ìš”ì•½ í•¨ìˆ˜ ì •ì˜ ---
async def summarize_text(model, text_to_summarize, max_sentences=3):
    """ Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤. """
    print(f"DEBUG: summarize_text í˜¸ì¶œë¨ - ìš”ì•½ ëŒ€ìƒ (ì‹œì‘): '{text_to_summarize[:50]}...'")
    try:
        summary_prompt = prompts.SUMMARIZE_PROMPT_TEMPLATE.format(text_to_summarize=text_to_summarize)
        generation_config_summary = genai_types.GenerationConfig(max_output_tokens=200)
        summary_response = await model.generate_content_async(summary_prompt, generation_config=generation_config_summary)
        if summary_response and summary_response.text:
            summarized_text = summary_response.text.strip()
            print(f"DEBUG: ìš”ì•½ ì„±ê³µ - ìš”ì•½ ê²°ê³¼: {summarized_text}")
            return summarized_text
        else: print(f"ê²½ê³ : ìš”ì•½ API ì‘ë‹µ ë¹„ì—ˆê±°ë‚˜ ë¬¸ì œ ìˆìŒ."); return None
    except Exception as e: print(f"ì˜¤ë¥˜: ìš”ì•½ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"); return None


# --- ë´‡ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ---
@bot.event
async def on_ready():
    init_db()
    print(f'ë¡œê·¸ì¸ ì„±ê³µ: {bot.user.name} ({bot.user.id})')
    print(f'ì• í”Œë¦¬ì¼€ì´ì…˜ ID: {DISCORD_APP_ID}'); print('------')
    print('ë´‡ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤! DM ë©”ì‹œì§€ë¥¼ ê¸°ë‹¤ë¦½ë‹ˆë‹¤...')
    if not send_proactive_dm.is_running():
        try: print("DEBUG: ì„ í†¡ ì‘ì—… ì‹œì‘ ì‹œë„..."); send_proactive_dm.start(); print('DEBUG: ì„ í†¡ ë³´ë‚´ê¸° ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… start() í˜¸ì¶œ ì™„ë£Œ.')
        except Exception as e: print(f"ì˜¤ë¥˜: ì„ í†¡ ì‘ì—… ì‹œì‘(start) ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
    else: print("DEBUG: ì„ í†¡ ì‘ì—…ì€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")


@bot.event
async def on_message(message):
    # --- !!! ì „ì—­ ë³€ìˆ˜ ì‚¬ìš© ì„ ì–¸ í™•ì¸ !!! ---
    global user_message_buffers, user_timer_tasks
    # ------------------------------------
    if message.author == bot.user: return
    if message.guild is not None: return # DMë§Œ ì²˜ë¦¬

    ctx = await bot.get_context(message)
    if ctx.command is not None:
        print(f"DEBUG: on_message - ëª…ë ¹ì–´ ê°ì§€ë¨: '{message.content}' -> ì²˜ë¦¬ë¥¼ process_commandsì— ë„˜ê¹€")
        await bot.process_commands(message) # ëª…ë ¹ì–´ëŠ” ì—¬ê¸°ì„œ ì²˜ë¦¬
        return

    # ì¼ë°˜ DM ë©”ì‹œì§€ ë²„í¼ë§ ë° íƒ€ì´ë¨¸ ì²˜ë¦¬
    user_id = message.author.id
    print(f"[DM ìˆ˜ì‹ ] {message.author.name}: {message.content}")
    if user_id not in user_message_buffers: user_message_buffers[user_id] = []
    user_message_buffers[user_id].append(message)
    print(f"DEBUG: ë©”ì‹œì§€ ë²„í¼ ì¶”ê°€ë¨ - ì‚¬ìš©ì ID: {user_id}, í˜„ì¬ ë²„í¼ í¬ê¸°: {len(user_message_buffers[user_id])}")
    if user_id in user_timer_tasks:
        existing_task = user_timer_tasks[user_id]
        if not existing_task.done(): print(f"DEBUG: ê¸°ì¡´ íƒ€ì´ë¨¸ ì·¨ì†Œ ì‹œë„ - ì‚¬ìš©ì ID: {user_id}"); existing_task.cancel()

    async def delayed_process(uid):
        try:
            await asyncio.sleep(20)
            print(f"DEBUG: 20ì´ˆ íƒ€ì´ë¨¸ ë§Œë£Œ - ì‚¬ìš©ì ID: {uid}, ì²˜ë¦¬ í•¨ìˆ˜ í˜¸ì¶œ ì‹œë„.")
            await process_message_batch(uid)
        except asyncio.CancelledError: print(f"DEBUG: íƒ€ì´ë¨¸ ì‘ì—… ì •ìƒ ì·¨ì†Œë¨ (ìƒˆ ë©”ì‹œì§€ ìˆ˜ì‹ ) - ì‚¬ìš©ì ID: {uid}")
        except Exception as e:
             print(f"ì˜¤ë¥˜: delayed_process ì‘ì—… ì¤‘ ì˜ˆì™¸ ë°œìƒ - ì‚¬ìš©ì ID: {uid}, ì˜¤ë¥˜: {e}"); traceback.print_exc()
             # --- !!! ì—¬ê¸° ë“¤ì—¬ì“°ê¸° í™•ì¸ !!! ---
             if uid in user_timer_tasks:
                 del user_timer_tasks[uid] # if ì•ˆì— ìˆì–´ì•¼ í•¨
                 print(f"DEBUG: ì˜¤ë¥˜ ë°œìƒ í›„ íƒ€ì´ë¨¸ ì‘ì—… ì •ë¦¬ë¨ - ì‚¬ìš©ì ID: {uid}")
             if uid in user_message_buffers:
                 del user_message_buffers[uid] # if ì•ˆì— ìˆì–´ì•¼ í•¨
                 print(f"DEBUG: ì˜¤ë¥˜ ë°œìƒ í›„ ë©”ì‹œì§€ ë²„í¼ ì •ë¦¬ë¨ - ì‚¬ìš©ì ID: {uid}")
             # ---------------------------

    print(f"DEBUG: ìƒˆ íƒ€ì´ë¨¸ ì‹œì‘ (20ì´ˆ) - ì‚¬ìš©ì ID: {user_id}")
    user_timer_tasks[user_id] = asyncio.create_task(delayed_process(user_id))


# --- ì„ í†¡ ë³´ë‚´ëŠ” ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… (ìš”ì•½ ë¡œì§ ì¶”ê°€ë¨) ---
@tasks.loop(minutes=30)
async def send_proactive_dm():
    try:
        user = await bot.fetch_user(TARGET_USER_ID)
        if user:
            print(f"ì„ í†¡ ëŒ€ìƒ í™•ì¸: {user.name} ({TARGET_USER_ID})")
            target_user_history, target_user_likability = load_user_data(TARGET_USER_ID)
            print(f"DEBUG: ì„ í†¡ - ë¡œë“œë¨ -> ê¸°ë¡ (ì´ {len(target_user_history)} í„´), í˜¸ê°ë„: {target_user_likability}")
            proactive_instruction = prompts.PROACTIVE_DM_PROMPT_TEMPLATE.format(user_display_name=user.display_name)
            history_with_instruction = target_user_history.copy()
            history_with_instruction.append({'role': 'user', 'parts': [proactive_instruction]})
            print(f"DEBUG: ì„ í†¡ - Geminiì—ê²Œ ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸(ë§ˆì§€ë§‰ ì§€ì‹œ): {proactive_instruction}")

            message_to_send_full = random.choice(prompts.PROACTIVE_DM_FALLBACKS)
            generated_text = ""

            try:
                print("DEBUG: ì„ í†¡ - 1ë‹¨ê³„: ì „ì²´ ì‘ë‹µ ìƒì„± ì‹œë„...")
                response = await model.generate_content_async(history_with_instruction)
                if response and response.text: generated_text = response.text.strip(); message_to_send_full = generated_text; print(f"Gemini ìƒì„± ë©”ì‹œì§€ (ì„ í†¡, ì „ì²´): {message_to_send_full[:100]}...")
                else: print(f"ê²½ê³ : Gemini ì‘ë‹µ ë¹„ì—ˆê±°ë‚˜ ì°¨ë‹¨ë¨. ê¸°ë³¸ ë©”ì‹œì§€ ì‚¬ìš©.")
            except Exception as e: print(f"ì˜¤ë¥˜: Gemini ë©”ì‹œì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {e}")

            # 2ë‹¨ê³„: ê¸¸ì´ í™•ì¸ ë° í•„ìš”ì‹œ ìš”ì•½
            final_text_to_send = message_to_send_full
            sentences = re.split(r'(?<=[.?!])\s+', message_to_send_full)
            if len(sentences) > 3:
                print(f"DEBUG: ì„ í†¡ - ë‹µë³€ì´ {len(sentences)} ë¬¸ì¥ìœ¼ë¡œ ê¸¸ì–´ì„œ ìš”ì•½ ì‹œë„...")
                summarized_text = await summarize_text(model, message_to_send_full)
                if summarized_text: final_text_to_send = summarized_text
                else: print("ê²½ê³ : ì„ í†¡ ìš”ì•½ ì‹¤íŒ¨. ì›ë³¸ ë‹µë³€ì˜ ì²« 3ë¬¸ì¥ ì‚¬ìš©."); final_text_to_send = " ".join(sentences[:3])
            else: print("DEBUG: ì„ í†¡ - ë‹µë³€ì´ 3ë¬¸ì¥ ì´í•˜ì´ë¯€ë¡œ ì›ë³¸ ì‚¬ìš©.")

            # 3ë‹¨ê³„: ìµœì¢… í…ìŠ¤íŠ¸ ë¶„í•  ì „ì†¡ ë° DB ì €ì¥
            print(f"ì„ í†¡ ì‹œë„ -> User ID: {TARGET_USER_ID}, ë©”ì‹œì§€ (ìµœì¢…): {final_text_to_send[:100]}...")
            if final_text_to_send:
                 final_sentences = re.split(r'(?<=[.?!])\s+', final_text_to_send)
                 for sentence in final_sentences:
                     sentence = sentence.strip()
                     if sentence: await user.send(sentence); await asyncio.sleep(random.uniform(1.0, 2.0))
                 print(f"ì„ í†¡ ì„±ê³µ (ë¶„í•  ì „ì†¡ ì™„ë£Œ) -> User ID: {TARGET_USER_ID}")
                 final_history_to_save = target_user_history
                 final_history_to_save.append({'role': 'model', 'parts': [message_to_send_full]}) # ì›ë³¸ ì „ì²´ ì €ì¥
                 save_user_data(TARGET_USER_ID, final_history_to_save, target_user_likability)
                 print(f"ì„ í†¡ ë‚´ìš©(ì›ë³¸) DB ì €ì¥ ì™„ë£Œ -> User ID: {TARGET_USER_ID}, í˜¸ê°ë„: {target_user_likability}")
            else: print(f"ê²½ê³ : ìµœì¢…ì ìœ¼ë¡œ ë³´ë‚¼ ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
    except discord.NotFound: print(f"ì˜¤ë¥˜: ì„ í†¡ ëŒ€ìƒ ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ID: {TARGET_USER_ID})")
    except discord.Forbidden: print(f"ì˜¤ë¥˜: ì„ í†¡ ëŒ€ìƒ ì‚¬ìš©ìì—ê²Œ DMì„ ë³´ë‚¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤ (ID: {TARGET_USER_ID})")
    except Exception as e: print(f"ì„ í†¡ ì‘ì—… ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")


@send_proactive_dm.before_loop
async def before_proactive_dm():
    print('DEBUG: ì„ í†¡ before_loop ì§„ì….')
    await bot.wait_until_ready()
    print('DEBUG: ì„ í†¡ before_loop - ë´‡ ì¤€ë¹„ ì™„ë£Œë¨.')
    print('ì„ í†¡ ì‘ì—…: ë´‡ ì¤€ë¹„ ì™„ë£Œ, ë£¨í”„ ì‹œì‘.')

@send_proactive_dm.error
async def send_proactive_dm_error(error):
    print(f"ì˜¤ë¥˜: ì„ í†¡ ì‘ì—… ë£¨í”„(@tasks.loop) ë‚´ì—ì„œ ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì˜ˆì™¸ ë°œìƒ!")
    traceback.print_exception(type(error), error, error.__traceback__)


# --- Cog ë¡œë”©ì„ ìœ„í•œ ë³„ë„ async í•¨ìˆ˜ ---
async def load_cogs():
    print("Cog ë¡œë”© ì‹œì‘ (load_cogs í•¨ìˆ˜)...")
    cog_loaded = False
    if not os.path.exists('./cogs'): print("ê²½ê³ : './cogs' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return
    for filename in os.listdir('./cogs'):
        if filename.endswith('.py'):
            extension_name = f'cogs.{filename[:-3]}'
            try: await bot.load_extension(extension_name); print(f" - Cog ë¡œë“œ ì„±ê³µ: {extension_name}"); cog_loaded = True
            except Exception as e: print(f" ! Cog ë¡œë“œ ì‹¤íŒ¨: {extension_name}\n   ì˜¤ë¥˜: {e}"); traceback.print_exc()
    if not cog_loaded: print("ê²½ê³ : ë¡œë“œëœ Cogê°€ ì—†ìŠµë‹ˆë‹¤."); print("------")


# --- ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì§„ì…ì  ---
if __name__ == "__main__":
    try:
        print("DEBUG: Cog ë¡œë”© ì‹œë„ (asyncio.run(load_cogs()) í˜¸ì¶œ ì „).")
        asyncio.run(load_cogs())
        print("DEBUG: Cog ë¡œë”© ì™„ë£Œë¨.")
        print("------")
        print("DEBUG: bot.run(DISCORD_TOKEN) í˜¸ì¶œ ì‹œë„...")
        bot.run(DISCORD_TOKEN) # ë´‡ ì‹¤í–‰
    except KeyboardInterrupt: print("ì‚¬ìš©ìì— ì˜í•´ ë´‡ ì‹¤í–‰ ì¤‘ë‹¨ë¨ (KeyboardInterrupt).")
    except discord.errors.LoginFailure: print("ì˜¤ë¥˜: ë””ìŠ¤ì½”ë“œ ë´‡ í† í°ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    except Exception as e: print(f"ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ ìµœìƒìœ„ ë ˆë²¨ ì˜ˆì™¸ ë°œìƒ: {e}"); traceback.print_exc()
    finally: print("ë´‡ í”„ë¡œê·¸ë¨ ì¢…ë£Œ.")